{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D\n",
    "from keras.layers import MaxPooling2D\n",
    "from keras.layers import Flatten\n",
    "from keras.layers import Dense\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From E:\\anaconda2\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:4070: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "classifier = Sequential()\n",
    "#Select 6 Convolution of size 3*3 , Input size of image is 32*32*3, it is a RGB image\n",
    "classifier.add(Conv2D(6, kernel_size=(5,5), activation='relu', input_shape=(64,64, 3)))\n",
    "#The output of the Convolution layer is 60*60*6 \n",
    "#Trainable parameters is (5 * 5 + 1) * 6= 156; \n",
    "#(5 * 5 = 25 unit parameters and one bias parameter per filter, a total of 6 filters)\n",
    "\n",
    "classifier.add( MaxPooling2D( pool_size=(3,3)))\n",
    "#The output of the Maximum Pooling layer is 30*30*6\n",
    "\n",
    "#The input matrix size of this layer is 30 * 30 * 6, the filter size used is 3 * 3, and the depth is 16. This layer does not use all 0 padding, and the step size is 1.\n",
    "# The output matrix size of this layer is 28 * 28 * 16.\n",
    "classifier.add(Conv2D(16, kernel_size=(3,3), activation='relu'))\n",
    "#The output of the Second Convolution layer is (30-3+1)=28\n",
    "classifier.add( MaxPooling2D( pool_size=(2,2)))\n",
    "#The output of the Maximum Pooling layer is 14*14*16\n",
    "classifier.add(Conv2D(16, kernel_size=(5,5), activation='relu'))\n",
    "#The output of the Second Convolution layer is (14-5+1)=10; 10*10*16\n",
    "classifier.add( MaxPooling2D( pool_size=(2,2)))\n",
    "#The output of the Maximum Pooling layer is 5*5*16\n",
    "# The input matrix size of this layer is 5 * 5 * 16. This layer is called a convolution layer in the LeNet-5 paper, but because the size of the filter is 5 * 5, #\n",
    "# So it is not different from the fully connected layer. If the nodes in the 5 * 5 * 16 matrix are pulled into a vector, then this layer is the same as the fully connected layer.\n",
    "# The number of output nodes in this layer is 120, with a total of 5 * 5 * 16 * 120 + 120 = 48120 parameters.\n",
    "classifier.add(Flatten())\n",
    "classifier.add(Dense(120, activation='relu'))\n",
    "\n",
    "# The number of input nodes in this layer is 120 and the number of output nodes is 84. The total parameter is 120 * 84 + 84 = 10164 (w + b)\n",
    "classifier.add(Dense(84, activation='relu'))\n",
    "classifier.add(Dense(2, activation='softmax'))\n",
    "classifier.compile(loss=keras.metrics.categorical_crossentropy, optimizer=keras.optimizers.Adam(), metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 276 images belonging to 2 classes.\n",
      "Found 40 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "from fastai import *\n",
    "from fastai.vision import *\n",
    "\n",
    "# Part 2 - Fitting the CNN to the images\n",
    "\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "\n",
    "train_data = ImageDataGenerator(rescale = 1./255,\n",
    "                                   shear_range = 0.2,\n",
    "                                   zoom_range = 0.2,\n",
    "                                   horizontal_flip = True)\n",
    "\n",
    "\n",
    "test_data = ImageDataGenerator(rescale = 1./255,\n",
    "                                   shear_range = 0.2,\n",
    "                                   zoom_range = 0.2,\n",
    "                                   horizontal_flip = True)\n",
    "\n",
    "\n",
    "training_set = train_data.flow_from_directory(r\"C:\\Users\\kriti\\OneDrive\\Desktop\\6th sem\\IP CS313a\\IP project\\Matlab Code and dataset\\train\",\n",
    "                                                 target_size = (64, 64),\n",
    "                                                 batch_size = 32,\n",
    "                                                 class_mode = 'categorical')\n",
    "test_set = test_data.flow_from_directory(r\"C:\\Users\\kriti\\OneDrive\\Desktop\\6th sem\\IP CS313a\\IP project\\Matlab Code and dataset\\test\",\n",
    "                                            target_size = (64, 64),\n",
    "                                            batch_size = 32,\n",
    "                                            class_mode = 'categorical')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From E:\\anaconda2\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n",
      "Epoch 1/30\n",
      "10/10 [==============================] - 18s 2s/step - loss: 0.6870 - accuracy: 0.5325 - val_loss: 0.6652 - val_accuracy: 0.6161\n",
      "Epoch 2/30\n",
      "10/10 [==============================] - 2s 195ms/step - loss: 0.6538 - accuracy: 0.6201 - val_loss: 0.5589 - val_accuracy: 0.6818\n",
      "Epoch 3/30\n",
      "10/10 [==============================] - 2s 171ms/step - loss: 0.5963 - accuracy: 0.6753 - val_loss: 0.5141 - val_accuracy: 0.7679\n",
      "Epoch 4/30\n",
      "10/10 [==============================] - 2s 186ms/step - loss: 0.5693 - accuracy: 0.7230 - val_loss: 0.9638 - val_accuracy: 0.7273\n",
      "Epoch 5/30\n",
      "10/10 [==============================] - 2s 167ms/step - loss: 0.5365 - accuracy: 0.7338 - val_loss: 0.4744 - val_accuracy: 0.8125\n",
      "Epoch 6/30\n",
      "10/10 [==============================] - 3s 297ms/step - loss: 0.5056 - accuracy: 0.7750 - val_loss: 0.2203 - val_accuracy: 0.8295\n",
      "Epoch 7/30\n",
      "10/10 [==============================] - 2s 170ms/step - loss: 0.5404 - accuracy: 0.7331 - val_loss: 0.3843 - val_accuracy: 0.8304\n",
      "Epoch 8/30\n",
      "10/10 [==============================] - 2s 242ms/step - loss: 0.5215 - accuracy: 0.7281 - val_loss: 0.6359 - val_accuracy: 0.7841\n",
      "Epoch 9/30\n",
      "10/10 [==============================] - 2s 182ms/step - loss: 0.4372 - accuracy: 0.7838 - val_loss: 0.3300 - val_accuracy: 0.8571\n",
      "Epoch 10/30\n",
      "10/10 [==============================] - 2s 202ms/step - loss: 0.4701 - accuracy: 0.7669 - val_loss: 0.6222 - val_accuracy: 0.7955\n",
      "Epoch 11/30\n",
      "10/10 [==============================] - 2s 179ms/step - loss: 0.5596 - accuracy: 0.7125 - val_loss: 0.6841 - val_accuracy: 0.7321\n",
      "Epoch 12/30\n",
      "10/10 [==============================] - 2s 170ms/step - loss: 0.4866 - accuracy: 0.7500 - val_loss: 0.5312 - val_accuracy: 0.8182\n",
      "Epoch 13/30\n",
      "10/10 [==============================] - 2s 161ms/step - loss: 0.4782 - accuracy: 0.7760 - val_loss: 0.5561 - val_accuracy: 0.7679\n",
      "Epoch 14/30\n",
      "10/10 [==============================] - 2s 161ms/step - loss: 0.4634 - accuracy: 0.7727 - val_loss: 0.4821 - val_accuracy: 0.8523\n",
      "Epoch 15/30\n",
      "10/10 [==============================] - 2s 214ms/step - loss: 0.4280 - accuracy: 0.8149 - val_loss: 0.3988 - val_accuracy: 0.8304\n",
      "Epoch 16/30\n",
      "10/10 [==============================] - 2s 215ms/step - loss: 0.4343 - accuracy: 0.7955 - val_loss: 0.1650 - val_accuracy: 0.8523\n",
      "Epoch 17/30\n",
      "10/10 [==============================] - 2s 194ms/step - loss: 0.4539 - accuracy: 0.8149 - val_loss: 0.4215 - val_accuracy: 0.8482\n",
      "Epoch 18/30\n",
      "10/10 [==============================] - 2s 206ms/step - loss: 0.3797 - accuracy: 0.8474 - val_loss: 0.1572 - val_accuracy: 0.8636\n",
      "Epoch 19/30\n",
      "10/10 [==============================] - 2s 158ms/step - loss: 0.3586 - accuracy: 0.8539 - val_loss: 0.4712 - val_accuracy: 0.8125\n",
      "Epoch 20/30\n",
      "10/10 [==============================] - 2s 177ms/step - loss: 0.3813 - accuracy: 0.8279 - val_loss: 0.0265 - val_accuracy: 0.8182\n",
      "Epoch 21/30\n",
      "10/10 [==============================] - 2s 204ms/step - loss: 0.3701 - accuracy: 0.8442 - val_loss: 0.4040 - val_accuracy: 0.8393\n",
      "Epoch 22/30\n",
      "10/10 [==============================] - 2s 208ms/step - loss: 0.3816 - accuracy: 0.8214 - val_loss: 0.6791 - val_accuracy: 0.8864\n",
      "Epoch 23/30\n",
      "10/10 [==============================] - 2s 156ms/step - loss: 0.3772 - accuracy: 0.8312 - val_loss: 0.3377 - val_accuracy: 0.9107\n",
      "Epoch 24/30\n",
      "10/10 [==============================] - 2s 156ms/step - loss: 0.2981 - accuracy: 0.8919 - val_loss: 0.4407 - val_accuracy: 0.8750\n",
      "Epoch 25/30\n",
      "10/10 [==============================] - 2s 193ms/step - loss: 0.2924 - accuracy: 0.8506 - val_loss: 0.2080 - val_accuracy: 0.9107\n",
      "Epoch 26/30\n",
      "10/10 [==============================] - 2s 219ms/step - loss: 0.2681 - accuracy: 0.8831 - val_loss: 0.4267 - val_accuracy: 0.8636\n",
      "Epoch 27/30\n",
      "10/10 [==============================] - 8s 784ms/step - loss: 0.2998 - accuracy: 0.8734 - val_loss: 0.2865 - val_accuracy: 0.9107\n",
      "Epoch 28/30\n",
      "10/10 [==============================] - 6s 618ms/step - loss: 0.2683 - accuracy: 0.8799 - val_loss: 1.5797 - val_accuracy: 0.8750\n",
      "Epoch 29/30\n",
      "10/10 [==============================] - 5s 516ms/step - loss: 0.2141 - accuracy: 0.9189 - val_loss: 0.6208 - val_accuracy: 0.8839\n",
      "Epoch 30/30\n",
      "10/10 [==============================] - 2s 197ms/step - loss: 0.2841 - accuracy: 0.8875 - val_loss: 0.4441 - val_accuracy: 0.9318\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x27c0b312388>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier.fit_generator(training_set,\n",
    "                         steps_per_epoch = 10,\n",
    "                         epochs = 30,\n",
    "                         validation_data = test_set,    \n",
    "                         validation_steps = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1. 0.]]\n",
      "NO\n"
     ]
    }
   ],
   "source": [
    "# Part 3 - Making new predictions\n",
    "import numpy as np\n",
    "from keras.preprocessing import image\n",
    "test_image = image.load_img(r\"C:\\Users\\kriti\\OneDrive\\Desktop\\brain mri\\ex4.jpg\", target_size = (64,64))\n",
    "\n",
    "test_image = image.img_to_array(test_image)\n",
    "test_image = np.expand_dims(test_image, axis = 0)\n",
    "\n",
    "result = classifier.predict(test_image)\n",
    "\n",
    "training_set.class_indices\n",
    "print(result)\n",
    "if result[0][0] == 1:\n",
    "    prediction = 'NO'\n",
    "    print(prediction)\n",
    "else:\n",
    "    prediction = 'YES'\n",
    "    print(prediction)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='4' class='' max='5' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      80.00% [4/5 06:14<01:33]\n",
       "    </div>\n",
       "    \n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1.218720</td>\n",
       "      <td>#na#</td>\n",
       "      <td>01:32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1.228465</td>\n",
       "      <td>#na#</td>\n",
       "      <td>01:29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1.150728</td>\n",
       "      <td>#na#</td>\n",
       "      <td>01:31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1.613679</td>\n",
       "      <td>#na#</td>\n",
       "      <td>01:39</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>\n",
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='5' class='' max='20' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      25.00% [5/20 00:24<01:12 3.3561]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR Finder is complete, type {learner_name}.recorder.plot() to see the graph.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.956554</td>\n",
       "      <td>1.001933</td>\n",
       "      <td>0.740000</td>\n",
       "      <td>01:44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1.089817</td>\n",
       "      <td>1.161637</td>\n",
       "      <td>0.620000</td>\n",
       "      <td>01:47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1.004581</td>\n",
       "      <td>1.845354</td>\n",
       "      <td>0.760000</td>\n",
       "      <td>01:49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.974717</td>\n",
       "      <td>0.597029</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>01:42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.781769</td>\n",
       "      <td>0.258100</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>01:43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.617121</td>\n",
       "      <td>0.275394</td>\n",
       "      <td>0.860000</td>\n",
       "      <td>01:38</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 400x400 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# part 4 Plotting the confusion matrix\n",
    "DATA_DIR=r'C:\\Users\\kriti\\OneDrive\\Desktop\\6th sem\\IP CS313a\\IP project\\Matlab Code and dataset\\brain_tumor_dataset'\n",
    "data = ImageDataBunch.from_folder(DATA_DIR, train=\".\", \n",
    "                                  valid_pct=0.2,\n",
    "                                  ds_tfms=get_transforms(flip_vert=True, max_warp=0),\n",
    "                                  size=224,bs=10, \n",
    "                                  num_workers=0).normalize(imagenet_stats)\n",
    "                                                          \n",
    "learn = cnn_learner(data, models.resnet34, metrics=accuracy, model_dir=r\"C:\\Users\\kriti\\OneDrive\\Desktop\\6th sem\\IP CS313a\\IP project\\Matlab Code and dataset\\brain_tumor_dataset\")\n",
    "learn.lr_find()\n",
    "learn.fit_one_cycle(6,1e-2)\n",
    "interp = ClassificationInterpretation.from_learner(learn)\n",
    "interp.plot_confusion_matrix(figsize=(8,8), dpi=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
